{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0-Dr6VmUTda",
        "outputId": "35475a1b-10d2-442f-9d64-a418b4f9e7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "# ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ignore a specific warning\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# generate a warning\n",
        "warnings.warn(\"This is a warning\", DeprecationWarning)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/rt_reviews.csv', encoding='latin-1')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "dwc8uO42Ubdl",
        "outputId": "d0e25932-83a2-480d-bbba-121219aabf15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(480000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Freshness                                             Review\n",
              "0     fresh   Manakamana doesn't answer any questions, yet ...\n",
              "1     fresh   Wilfully offensive and powered by a chest-thu...\n",
              "2    rotten   It would be difficult to imagine material mor...\n",
              "3    rotten   Despite the gusto its star brings to the role...\n",
              "4    rotten   If there was a good idea at the core of this ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c40ceb6-2e49-4a62-a6ea-75c3ba16e2ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freshness</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fresh</td>\n",
              "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fresh</td>\n",
              "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rotten</td>\n",
              "      <td>It would be difficult to imagine material mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rotten</td>\n",
              "      <td>Despite the gusto its star brings to the role...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rotten</td>\n",
              "      <td>If there was a good idea at the core of this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c40ceb6-2e49-4a62-a6ea-75c3ba16e2ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c40ceb6-2e49-4a62-a6ea-75c3ba16e2ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c40ceb6-2e49-4a62-a6ea-75c3ba16e2ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide the dataset into train and test sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Divide the test set into dev and test sets\n",
        "dev_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the number of examples in each set\n",
        "print(f\"train set:{train_data.shape}\")\n",
        "print(f\"dev set:{dev_data.shape}\")\n",
        "print(f\"test set:{test_data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOoYSmMWUikl",
        "outputId": "49f49622-c806-465b-937f-671146d91630"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:(336000, 2)\n",
            "dev set:(72000, 2)\n",
            "test set:(72000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Tokenize the text\n",
        "train_tokens = [review.lower().split() for review in train_data['Review']]\n",
        "\n",
        "# Count the frequency of each word in the training set\n",
        "word_counts = Counter([word for review in train_tokens for word in review])\n",
        "\n",
        "# Create a list of words that occur more than 5 times in the training set\n",
        "vocab_list = [word for word, count in word_counts.items() if count > 5]\n",
        "\n",
        "# Create a reverse index that maps each word to its index in the vocabulary\n",
        "vocab_index = {word: i for i, word in enumerate(vocab_list)}\n",
        "\n",
        "# Print the size of the vocabulary\n",
        "print(f\"Size of vocabulary: {len(vocab_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByiucOLcUm9Q",
        "outputId": "0b4ed745-d2cc-45cf-c5f4-a1784da8a5b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 51275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_PmdHgTBpuY",
        "outputId": "a4ea8321-17b9-410b-8a54-7cca54bde843"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['does',\n",
              " 'one',\n",
              " 'really',\n",
              " 'have',\n",
              " 'to',\n",
              " 'so',\n",
              " \"christ's\",\n",
              " 'story',\n",
              " 'in',\n",
              " 'order',\n",
              " 'make',\n",
              " 'it',\n",
              " 'relevant',\n",
              " \"today's\",\n",
              " 'audiences?',\n",
              " 'people',\n",
              " 'richer',\n",
              " 'than',\n",
              " 'you',\n",
              " 'get',\n",
              " 'paid',\n",
              " 'come',\n",
              " 'up',\n",
              " 'with',\n",
              " 'this',\n",
              " 'stuff.',\n",
              " 'while',\n",
              " \"doesn't\",\n",
              " 'exactly',\n",
              " 'take',\n",
              " 'your',\n",
              " 'breath',\n",
              " 'away,',\n",
              " 'small',\n",
              " 'coming-of-age',\n",
              " 'will',\n",
              " 'smile',\n",
              " 'about',\n",
              " 'how',\n",
              " 'film',\n",
              " 'can',\n",
              " 'even',\n",
              " 'the',\n",
              " 'slightest',\n",
              " 'of',\n",
              " 'ideas.',\n",
              " 'bad',\n",
              " 'movie,',\n",
              " 'folks.',\n",
              " \"don't\",\n",
              " 'be',\n",
              " 'a',\n",
              " 'fool',\n",
              " 'and',\n",
              " 'waste',\n",
              " 'time',\n",
              " 'money',\n",
              " 'on',\n",
              " 'it.',\n",
              " '(full',\n",
              " 'content',\n",
              " 'review',\n",
              " 'for',\n",
              " 'parents',\n",
              " '-',\n",
              " 'sex,',\n",
              " 'profanity,',\n",
              " 'nudity,',\n",
              " 'etc.',\n",
              " 'also',\n",
              " 'available)',\n",
              " 'all',\n",
              " 'hat,',\n",
              " 'no',\n",
              " 'tentacles.',\n",
              " 'last',\n",
              " 'flag',\n",
              " 'flying',\n",
              " 'lacks',\n",
              " 'casual,',\n",
              " 'lived-in',\n",
              " 'realism',\n",
              " 'usually',\n",
              " 'find',\n",
              " 'linklater',\n",
              " 'film.',\n",
              " 'buy',\n",
              " 'men',\n",
              " 'as',\n",
              " 'pals,',\n",
              " 'premise',\n",
              " 'connection',\n",
              " 'that',\n",
              " 'caused',\n",
              " 'doc',\n",
              " 'seek',\n",
              " 'out',\n",
              " 'these',\n",
              " 'is',\n",
              " 'not',\n",
              " 'visible',\n",
              " 'screen.',\n",
              " \"it's\",\n",
              " 'character',\n",
              " 'development',\n",
              " 'fueling',\n",
              " 'fire.',\n",
              " \"ade's\",\n",
              " 'odd',\n",
              " 'captivating',\n",
              " 'speaks',\n",
              " 'many',\n",
              " 'truths',\n",
              " 'boasts',\n",
              " 'probably',\n",
              " 'best',\n",
              " 'final',\n",
              " 'shot',\n",
              " 'festival.',\n",
              " 'tehran',\n",
              " 'taboo',\n",
              " 'fascinating',\n",
              " 'glimpse',\n",
              " 'into',\n",
              " \"iran's\",\n",
              " 'patriarchal',\n",
              " 'religious',\n",
              " 'society',\n",
              " 'affects',\n",
              " 'women.',\n",
              " 'dark',\n",
              " 'film,',\n",
              " 'offering',\n",
              " 'unsettling',\n",
              " 'images',\n",
              " 'uncomfortable',\n",
              " 'situations,',\n",
              " 'has',\n",
              " 'moments',\n",
              " 'greatness,',\n",
              " 'just',\n",
              " 'enough',\n",
              " 'them',\n",
              " 'generate',\n",
              " 'riveting',\n",
              " 'sit.',\n",
              " 'nolan',\n",
              " 'cements',\n",
              " 'his',\n",
              " 'position',\n",
              " \"hollywood's\",\n",
              " 'premier',\n",
              " 'purveyor',\n",
              " 'blockbuster',\n",
              " 'smarts.',\n",
              " 'love',\n",
              " 'sci-fi',\n",
              " 'films',\n",
              " 'few',\n",
              " 'things',\n",
              " 'like',\n",
              " 'it,',\n",
              " 'but',\n",
              " 'those',\n",
              " 'looking',\n",
              " 'slick',\n",
              " 'production',\n",
              " 'better',\n",
              " 'look',\n",
              " 'elsewhere.',\n",
              " 'shedding',\n",
              " 'light',\n",
              " 'world',\n",
              " 'atrocities',\n",
              " 'vital,',\n",
              " 'spelling',\n",
              " 'neon',\n",
              " 'deadly.',\n",
              " 'truly',\n",
              " 'wounds',\n",
              " 'wars',\n",
              " 'leave',\n",
              " 'who',\n",
              " 'fight',\n",
              " '--',\n",
              " 'lengths',\n",
              " 'which',\n",
              " 'crowe',\n",
              " 'go',\n",
              " 'convince',\n",
              " 'strong',\n",
              " 'cry,',\n",
              " 'sir.',\n",
              " 'cry.',\n",
              " 'from',\n",
              " 'heart',\n",
              " '...',\n",
              " 'chazelle',\n",
              " 'moment',\n",
              " 'wink',\n",
              " 'at',\n",
              " 'viewer.',\n",
              " \"he's\",\n",
              " 'he',\n",
              " 'believes',\n",
              " 'violet',\n",
              " 'sunsets,',\n",
              " 'movie',\n",
              " 'star',\n",
              " 'twinkly',\n",
              " 'planetarium',\n",
              " 'stars.',\n",
              " \"film's\",\n",
              " 'act',\n",
              " 'almost',\n",
              " 'completely',\n",
              " 'falling',\n",
              " 'blind,',\n",
              " 'machinations.',\n",
              " 'without',\n",
              " 'political',\n",
              " 'preaching',\n",
              " 'or',\n",
              " 'providing',\n",
              " 'traditional',\n",
              " 'social',\n",
              " 'commentary,',\n",
              " 'maoz',\n",
              " 'crafted',\n",
              " 'rare',\n",
              " 'human',\n",
              " 'drama,',\n",
              " 'gives',\n",
              " 'real',\n",
              " 'insights',\n",
              " 'horror',\n",
              " 'war.',\n",
              " 'an',\n",
              " 'worth',\n",
              " 'every',\n",
              " 'penny.',\n",
              " 'beautiful',\n",
              " 'creatures',\n",
              " 'terrible',\n",
              " 'twaddle.',\n",
              " 'though',\n",
              " 'whole',\n",
              " 'delivers',\n",
              " 'ample',\n",
              " 'thrills,',\n",
              " 'occasionally',\n",
              " 'encumbered',\n",
              " 'by',\n",
              " 'bland',\n",
              " 'voiceovers',\n",
              " 'lack',\n",
              " 'laughs',\n",
              " 'ambling',\n",
              " 'set',\n",
              " 'against',\n",
              " 'desert',\n",
              " 'dunes',\n",
              " 'looks',\n",
              " 'plausible,',\n",
              " 'its',\n",
              " 'furry',\n",
              " 'feet',\n",
              " 'seem',\n",
              " 'glide',\n",
              " 'once',\n",
              " 'lerman',\n",
              " 'finds',\n",
              " 'footing,',\n",
              " 'carries',\n",
              " 'right',\n",
              " 'amounts',\n",
              " 'nuance,',\n",
              " 'charm',\n",
              " 'angst.',\n",
              " \"isn't\",\n",
              " 'deep,',\n",
              " 'steinfeld',\n",
              " 'makes',\n",
              " 'watchable',\n",
              " \"there's\",\n",
              " 'amusing',\n",
              " 'support',\n",
              " 'woody',\n",
              " 'harrelson',\n",
              " 'her',\n",
              " 'wry',\n",
              " 'teacher.',\n",
              " \"year's\",\n",
              " '\"i',\n",
              " 'am',\n",
              " 'documentary',\n",
              " 'centers',\n",
              " 'past,',\n",
              " 'pertinence',\n",
              " 'culture',\n",
              " 'striking',\n",
              " 'utterly',\n",
              " 'devastating.',\n",
              " 'i',\n",
              " 'heartily',\n",
              " 'recommend',\n",
              " 'friends',\n",
              " 'family',\n",
              " 'older',\n",
              " 'feel-good',\n",
              " 'high',\n",
              " 'school',\n",
              " 'step.',\n",
              " 'kind',\n",
              " 'made',\n",
              " 'ryan',\n",
              " \"gosling's\",\n",
              " 'magnetic',\n",
              " 'performance.',\n",
              " 'cinema',\n",
              " 'rarely',\n",
              " 'comes',\n",
              " 'more',\n",
              " 'hard-hitting',\n",
              " '(in',\n",
              " 'yet',\n",
              " 'there',\n",
              " 'tenderness',\n",
              " 'around',\n",
              " 'rough',\n",
              " 'edges,',\n",
              " 'well',\n",
              " 'disarming',\n",
              " 'compassion',\n",
              " 'sort',\n",
              " 'characters',\n",
              " 'easily',\n",
              " 'dismissed',\n",
              " 'mere',\n",
              " 'monsters.',\n",
              " 'couple',\n",
              " 'robot',\n",
              " 'board',\n",
              " 'satellite',\n",
              " 'love,',\n",
              " 'because',\n",
              " \"you'll\",\n",
              " 'need',\n",
              " 'riff',\n",
              " 'own',\n",
              " 'commentary',\n",
              " 'track',\n",
              " 'through',\n",
              " 'if',\n",
              " 'late',\n",
              " '2000s',\n",
              " 'millennial',\n",
              " 'fare',\n",
              " 'may',\n",
              " 'suggest',\n",
              " 'disney',\n",
              " 'channel',\n",
              " 'classics',\n",
              " 'girl',\n",
              " '21st',\n",
              " 'dolls.',\n",
              " 'shudder',\n",
              " 'think',\n",
              " 'what',\n",
              " '3\"',\n",
              " 'might',\n",
              " 'bring.',\n",
              " 'courting',\n",
              " 'charlize',\n",
              " 'theron',\n",
              " 'plays',\n",
              " 'gag-inducing',\n",
              " 'katherine',\n",
              " 'heigl',\n",
              " 'rom-com.',\n",
              " 'revenant',\n",
              " 'throwback',\n",
              " 'wild',\n",
              " 'american',\n",
              " 'history,',\n",
              " 'team-up',\n",
              " 'iï¿½ï¿½ï¿½ï¿½rritu',\n",
              " 'dicaprio',\n",
              " 'era',\n",
              " 'bright',\n",
              " 'did',\n",
              " 'care',\n",
              " 'women',\n",
              " 'clearly,',\n",
              " 'rapace',\n",
              " 'fry',\n",
              " 'did.',\n",
              " 'shame',\n",
              " \"movie's\",\n",
              " 'script',\n",
              " \"wasn't\",\n",
              " 'communicate',\n",
              " 'work',\n",
              " 'they',\n",
              " 'had',\n",
              " 'done',\n",
              " 'fill',\n",
              " 'their',\n",
              " \"characters'\",\n",
              " 'backgrounds.',\n",
              " 'pileup',\n",
              " 'twists',\n",
              " 'red',\n",
              " 'herrings,',\n",
              " 'any',\n",
              " 'sense',\n",
              " 'whatsoever.',\n",
              " 'rocky',\n",
              " 'returns',\n",
              " 'long',\n",
              " 'outing',\n",
              " 'please',\n",
              " 'mainstream,',\n",
              " 'lets',\n",
              " 'down',\n",
              " 'fans',\n",
              " 'franchise.',\n",
              " 'could',\n",
              " 'use',\n",
              " 'least',\n",
              " 'levity.',\n",
              " 'only',\n",
              " \"we'll\",\n",
              " 'fighter,',\n",
              " 'good',\n",
              " 'enough.',\n",
              " 'sergei',\n",
              " 'loznitsa',\n",
              " 'writes',\n",
              " 'ideas',\n",
              " 'too',\n",
              " 'explicitly',\n",
              " 'dialogue,',\n",
              " 'deftly',\n",
              " 'employing',\n",
              " 'some',\n",
              " 'ironic',\n",
              " 'symbolism',\n",
              " 'criminally',\n",
              " 'fingernails',\n",
              " 'scraping',\n",
              " 'blackboard',\n",
              " 'ninety',\n",
              " 'minutes.',\n",
              " 'feels',\n",
              " 'false',\n",
              " 'platitudinous',\n",
              " 'calculated',\n",
              " 'crowd-pleaser',\n",
              " 'that,',\n",
              " 'despite',\n",
              " 'being',\n",
              " 'original',\n",
              " 'story,',\n",
              " 'poorly',\n",
              " 'condensed',\n",
              " 'novel',\n",
              " 'scripter',\n",
              " 'unable',\n",
              " 'choices.',\n",
              " 'force',\n",
              " 'majeure',\n",
              " 'follows',\n",
              " 'marriage',\n",
              " 'very',\n",
              " 'slippery',\n",
              " 'slope',\n",
              " 'eyes',\n",
              " 'wide',\n",
              " 'shut',\n",
              " 'turns',\n",
              " 'series',\n",
              " 'haphazard',\n",
              " 'revelations',\n",
              " 'little.',\n",
              " 'another',\n",
              " 'wretched',\n",
              " 'allen',\n",
              " 'release',\n",
              " 'round',\n",
              " 'hollywood',\n",
              " 'actors',\n",
              " 'chance',\n",
              " 'tick',\n",
              " 'him',\n",
              " 'off',\n",
              " 'lists',\n",
              " 'giving',\n",
              " 'us',\n",
              " 'much',\n",
              " 'enjoy',\n",
              " 'luca',\n",
              " \"guadagnino's\",\n",
              " 'latest',\n",
              " 'both',\n",
              " 'alluring',\n",
              " 'alienating',\n",
              " 'equal',\n",
              " 'measure.',\n",
              " \"that's\",\n",
              " 'part',\n",
              " 'parcel',\n",
              " 'beauty.',\n",
              " 'verbose',\n",
              " 'essay',\n",
              " 'never',\n",
              " 'successfully',\n",
              " 'surpasses',\n",
              " 'realm',\n",
              " 'academic',\n",
              " 'curiosity.',\n",
              " 'authentic,',\n",
              " 'are',\n",
              " 'true,',\n",
              " 'situation',\n",
              " 'hopeless',\n",
              " 'die-hard',\n",
              " \"won't\",\n",
              " 'able',\n",
              " 'resist',\n",
              " 'vardalos',\n",
              " 'lovely',\n",
              " 'screen',\n",
              " 'chemistry',\n",
              " 'heartfelt',\n",
              " 'reconnect',\n",
              " 'first',\n",
              " 'story.',\n",
              " 'casual',\n",
              " 'fan',\n",
              " 'mind',\n",
              " 'getting',\n",
              " 'chase',\n",
              " 'scenes',\n",
              " 'sag',\n",
              " 'debut',\n",
              " 'director',\n",
              " 'marcos',\n",
              " 'siega',\n",
              " 'disappoints',\n",
              " 'audiences',\n",
              " 'turn.',\n",
              " \"mcgregor's\",\n",
              " 'palpable',\n",
              " 'sincerity',\n",
              " 'cannot',\n",
              " 'obscure',\n",
              " 'smug',\n",
              " 'misogyny.',\n",
              " 'behind',\n",
              " 'central',\n",
              " 'tableau',\n",
              " 'starts',\n",
              " 'mundane,',\n",
              " 'shifts',\n",
              " 'tale',\n",
              " 'pain',\n",
              " 'sadness,',\n",
              " 'ends',\n",
              " 'note',\n",
              " 'mixed',\n",
              " 'tortured',\n",
              " 'understanding.',\n",
              " 'problem',\n",
              " 'such',\n",
              " 'lethal',\n",
              " 'pitch',\n",
              " 'nowhere',\n",
              " 'believable',\n",
              " 'build',\n",
              " 'die',\n",
              " 'hard',\n",
              " 'jean-luc',\n",
              " 'godard',\n",
              " 'appreciate',\n",
              " 'failed',\n",
              " 'experiment.',\n",
              " 'fan.',\n",
              " 'soul-stirring',\n",
              " 'way',\n",
              " 'relive',\n",
              " 'three',\n",
              " 'years,',\n",
              " 'miserable',\n",
              " 'see',\n",
              " '&',\n",
              " 'sing.',\n",
              " 'settles',\n",
              " 'groove',\n",
              " 'wikipedia',\n",
              " 'biopic,',\n",
              " 'telling',\n",
              " 'happened,',\n",
              " 'then',\n",
              " 'until',\n",
              " \"legend's\",\n",
              " '(of',\n",
              " 'course)',\n",
              " 'tastefully',\n",
              " 'death',\n",
              " 'expect',\n",
              " 'quality',\n",
              " 'acting',\n",
              " 'narrative',\n",
              " 'consistency',\n",
              " 'anything',\n",
              " 'want',\n",
              " 'bunch',\n",
              " 'faceless',\n",
              " 'guys',\n",
              " 'thoroughly',\n",
              " '[jason]',\n",
              " 'dig',\n",
              " 'one.',\n",
              " 'constantly',\n",
              " 'pointing',\n",
              " 'happens',\n",
              " 'movies',\n",
              " 'clever.',\n",
              " 'repeatedly',\n",
              " 'saying',\n",
              " '\"this',\n",
              " 'when',\n",
              " 'something',\n",
              " 'funny.',\n",
              " 'having',\n",
              " 'heroes',\n",
              " 'recognize',\n",
              " \"they're\",\n",
              " 'idea.',\n",
              " 'end,',\n",
              " 'solo',\n",
              " 'action',\n",
              " 'romp',\n",
              " 'hits',\n",
              " 'ground',\n",
              " 'running',\n",
              " 'breaks.',\n",
              " 'scene',\n",
              " 'rogue',\n",
              " \"one's\",\n",
              " 'darth',\n",
              " 'vader',\n",
              " 'moment.',\n",
              " 'heroes,',\n",
              " 'instead,',\n",
              " 'so-so.',\n",
              " 'visual',\n",
              " 'patina',\n",
              " 'strongly',\n",
              " 'reminds',\n",
              " 'tv',\n",
              " 'movie...',\n",
              " '[full',\n",
              " 'spanish]',\n",
              " 'vacationing',\n",
              " 'kids',\n",
              " 'remember,',\n",
              " 'let',\n",
              " 'alone',\n",
              " 'cheeky',\n",
              " 'little',\n",
              " 'half',\n",
              " 'hour',\n",
              " 'entertained',\n",
              " 'old',\n",
              " 'folks',\n",
              " 'century',\n",
              " 'ago.',\n",
              " 'seeing',\n",
              " 'handle',\n",
              " 'shallow',\n",
              " 'dull,',\n",
              " 'plastic',\n",
              " 'sake',\n",
              " 'unintentional',\n",
              " 'laughs.',\n",
              " 'faced',\n",
              " 'tough',\n",
              " 'competition',\n",
              " 'screens',\n",
              " 'big',\n",
              " 'little,',\n",
              " 'pursue',\n",
              " 'ferocious',\n",
              " 'deep',\n",
              " 'impression.',\n",
              " 'various',\n",
              " 'symbols',\n",
              " 'coalesce',\n",
              " 'metaphor',\n",
              " 'stand',\n",
              " 'stagnant',\n",
              " 'hollow',\n",
              " 'edges',\n",
              " 'frame.',\n",
              " 'personalities',\n",
              " 'brings',\n",
              " 'whom',\n",
              " 'were',\n",
              " 'forced',\n",
              " 'remain',\n",
              " 'silent',\n",
              " \"they'd\",\n",
              " 'seen',\n",
              " 'after',\n",
              " 'returning',\n",
              " 'worthy',\n",
              " 'widespread',\n",
              " 'altogether',\n",
              " 'predictable',\n",
              " 'skims',\n",
              " 'emotional',\n",
              " 'surface',\n",
              " 'episodic',\n",
              " 'narrative.',\n",
              " \"what's\",\n",
              " 'more,',\n",
              " 'vampire',\n",
              " 'conceit,',\n",
              " 'superficially',\n",
              " 'silly,',\n",
              " 'salutary',\n",
              " 'effect',\n",
              " 'throwing',\n",
              " 'mortality',\n",
              " 'stark',\n",
              " 'relief,',\n",
              " 'creating',\n",
              " 'carpe',\n",
              " 'diem',\n",
              " 'sensation',\n",
              " 'end',\n",
              " 'here',\n",
              " 'bana',\n",
              " 'certainly',\n",
              " 'weakest',\n",
              " 'necessarily',\n",
              " 'bring',\n",
              " 'new',\n",
              " 'table',\n",
              " 'been',\n",
              " 'expected',\n",
              " 'given',\n",
              " 'compelling',\n",
              " 'folklore',\n",
              " 'borrows',\n",
              " 'from.',\n",
              " 'instalment',\n",
              " 'franchise',\n",
              " 'opts',\n",
              " 'far',\n",
              " 'greater',\n",
              " 'supernatural',\n",
              " 'silliness',\n",
              " 'predecessors.',\n",
              " 'wishing',\n",
              " 'was',\n",
              " 'chicken',\n",
              " 'run',\n",
              " 'achieving',\n",
              " 'depth',\n",
              " 'where',\n",
              " 'are,',\n",
              " 'anderson',\n",
              " 'baumbach',\n",
              " 'create',\n",
              " 'affair',\n",
              " \"i'm\",\n",
              " 'sure',\n",
              " 'watching',\n",
              " 'over',\n",
              " 'over.',\n",
              " 'inventory',\n",
              " 'preoccupations',\n",
              " '13-year-old',\n",
              " 'boys.',\n",
              " 'empty,',\n",
              " 'efficient',\n",
              " 'thriller',\n",
              " 'leaves',\n",
              " 'cold',\n",
              " 'most',\n",
              " 'characters.',\n",
              " 'john',\n",
              " 'cusack',\n",
              " 'performance',\n",
              " 'life',\n",
              " 'horror.',\n",
              " 'everything',\n",
              " 'needed',\n",
              " 'amping',\n",
              " 'up,',\n",
              " 'amplifying',\n",
              " 'out.',\n",
              " 'less',\n",
              " 'always',\n",
              " 'more;',\n",
              " 'sometimes',\n",
              " 'more.',\n",
              " 'thing',\n",
              " 'practically',\n",
              " 'invites',\n",
              " 'tired',\n",
              " 'canned',\n",
              " 'laughter.',\n",
              " 'un',\n",
              " 'de',\n",
              " 'et',\n",
              " 'genre,',\n",
              " 'ï¿½ï¿½',\n",
              " 'la',\n",
              " 'dense',\n",
              " 'dumb',\n",
              " 'generally',\n",
              " 'unfunny,',\n",
              " 'moments.',\n",
              " 'park',\n",
              " 'chan-wook',\n",
              " 'drama',\n",
              " 'worldview.',\n",
              " 'drive',\n",
              " 'toward',\n",
              " 'cruelty',\n",
              " 'absolute',\n",
              " 'case,',\n",
              " 'absolutely',\n",
              " 'boring.',\n",
              " 'okay',\n",
              " 'know,',\n",
              " 'is.',\n",
              " \"i've\",\n",
              " 'walked',\n",
              " 'my',\n",
              " '(and',\n",
              " 'saw',\n",
              " 'city',\n",
              " 'angels',\n",
              " \"weren't\",\n",
              " 'reviewing',\n",
              " 'would',\n",
              " 'countless',\n",
              " 'problems',\n",
              " 'plague',\n",
              " 'misfire',\n",
              " 'south',\n",
              " 'african',\n",
              " 'neill',\n",
              " 'blomkamp,',\n",
              " 'above',\n",
              " 'total',\n",
              " 'incredulity',\n",
              " 'concerning',\n",
              " 'robotic',\n",
              " 'chappie',\n",
              " 'crushes',\n",
              " 'rubble',\n",
              " 'emotionally',\n",
              " 'incisive',\n",
              " 'initially',\n",
              " 'appears',\n",
              " 'be,',\n",
              " 'equally',\n",
              " 'ties',\n",
              " 'together',\n",
              " 'neatly',\n",
              " 'already',\n",
              " 'concise',\n",
              " 'time.',\n",
              " 'tiresome',\n",
              " 'interracial',\n",
              " 'custody',\n",
              " 'dramedy',\n",
              " 'white',\n",
              " 'righteously',\n",
              " 'dukes',\n",
              " 'black',\n",
              " 'melodrama.',\n",
              " 'plot',\n",
              " 'meanders',\n",
              " 'aimlessly',\n",
              " 'characters,',\n",
              " 'trio',\n",
              " 'minor',\n",
              " 'scrapes,',\n",
              " 'brushing',\n",
              " 'themselves',\n",
              " 'off,',\n",
              " 'moving',\n",
              " 'next',\n",
              " 'gilliam',\n",
              " 'making',\n",
              " 'paint',\n",
              " 'numbers',\n",
              " 'ultimate',\n",
              " 'achievement',\n",
              " 'remembering',\n",
              " 'great',\n",
              " 'spider-man',\n",
              " 'should',\n",
              " 'end:',\n",
              " 'fun,',\n",
              " 'heartfelt,',\n",
              " 'exciting',\n",
              " 'ever',\n",
              " 'losing',\n",
              " 'sight',\n",
              " 'beloved',\n",
              " 'iconic.',\n",
              " 'cute',\n",
              " 'cheesy',\n",
              " 'manages',\n",
              " 'tweak',\n",
              " 'zombie',\n",
              " 'lore',\n",
              " 'raising',\n",
              " 'bar',\n",
              " 'teen',\n",
              " 'romance',\n",
              " 'phase.',\n",
              " \"who've\",\n",
              " 'juvenile',\n",
              " 'humor,',\n",
              " 'offer.',\n",
              " 'unfortunately,',\n",
              " 'nothing',\n",
              " 'particularly',\n",
              " 'substantive,',\n",
              " 'either.',\n",
              " 'lucas',\n",
              " 'hedges,',\n",
              " 'nicole',\n",
              " 'kidman',\n",
              " ',',\n",
              " 'russell',\n",
              " 'lead',\n",
              " 'superb',\n",
              " 'cast',\n",
              " 'joel',\n",
              " \"edgerton's\",\n",
              " 'conversion',\n",
              " 'therapy',\n",
              " 'notes.',\n",
              " 'dinosaur',\n",
              " 'unsatisfying,',\n",
              " 'repetitive',\n",
              " 'themes',\n",
              " 'memorable',\n",
              " 'quite',\n",
              " 'forgettable.',\n",
              " 'be.',\n",
              " 'slogging',\n",
              " '75',\n",
              " 'minutes',\n",
              " 'trouble',\n",
              " 'curve',\n",
              " 'akin',\n",
              " 'baseball',\n",
              " 'game',\n",
              " 'ninth',\n",
              " 'solidly',\n",
              " 'old-fashioned',\n",
              " 'crime',\n",
              " 'ploughs',\n",
              " 'familiar',\n",
              " 'cops,',\n",
              " 'crooks',\n",
              " 'corruption',\n",
              " 'york',\n",
              " 'city.',\n",
              " \"'elysium'\",\n",
              " 'goes',\n",
              " 'overboard',\n",
              " 'loud,',\n",
              " 'jerky,',\n",
              " 'sequences.',\n",
              " 'decade',\n",
              " 'dominated',\n",
              " 'dreaded',\n",
              " 'remakes,',\n",
              " 'reimaginings',\n",
              " 'reboots',\n",
              " 'blockbuster.',\n",
              " 'basic',\n",
              " 'idea',\n",
              " 'provocative,',\n",
              " 'district',\n",
              " '9',\n",
              " 'lives',\n",
              " 'promise',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability of the occurrence\n",
        "total_docs = len(train_data)\n",
        "docs_with_the = sum(['the' in review for review in train_data['Review']])\n",
        "p_the = docs_with_the / total_docs\n",
        "print(f\"probabilty of 'the' occurence: {p_the}\")\n",
        "\n",
        "# Conditional probability based on the sentiment\n",
        "total_positive_docs = len(train_data[train_data['Freshness'] == 'fresh'])\n",
        "positive_docs_with_the = sum(['the' in review for review in train_data[train_data['Freshness'] == 'fresh']['Review']])\n",
        "p_the_given_positive = positive_docs_with_the / total_positive_docs\n",
        "print(f\"conditional probability of 'the' given positive sentiment: {p_the_given_positive}\")\n",
        "\n",
        "total_negative_docs = len(train_data[train_data['Freshness'] == 'rotten'])\n",
        "negative_docs_with_the = sum(['the' in review for review in train_data[train_data['Freshness'] == 'rotten']['Review']])\n",
        "p_the_given_negative = negative_docs_with_the / total_negative_docs\n",
        "print(f\"conditional probability of 'the' given negative sentiment: {p_the_given_negative}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWwrUGczEfnG",
        "outputId": "28f5a43d-e144-4380-87fe-e570e92815a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probabilty of 'the' occurence: 0.6529285714285714\n",
            "conditional probability of 'the' given positive sentiment: 0.653702612453349\n",
            "conditional probability of 'the' given negative sentiment: 0.6521545027589778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the probability of occurrence of each word in the training set\n",
        "word_probs = np.zeros(len(vocab_list))\n",
        "total_docs = len(train_data)\n",
        "for review in train_tokens:\n",
        "    for word in review:\n",
        "        if word in vocab_list:\n",
        "            word_probs[vocab_index[word]] += 1\n",
        "word_probs /= total_docs\n",
        "\n",
        "# Calculate the conditional probability of each word given the sentiment\n",
        "positive_docs = train_data[train_data['Freshness'] == 'fresh']\n",
        "negative_docs = train_data[train_data['Freshness'] == 'rotten']\n",
        "\n",
        "pos_word_counts = np.zeros(len(vocab_list))\n",
        "neg_word_counts = np.zeros(len(vocab_list))\n",
        "\n",
        "for review in positive_docs['Review']:\n",
        "    for word in review.lower().split():\n",
        "        if word in vocab_list:\n",
        "            pos_word_counts[vocab_index[word]] += 1\n",
        "\n",
        "for review in negative_docs['Review']:\n",
        "    for word in review.lower().split():\n",
        "        if word in vocab_list:\n",
        "            neg_word_counts[vocab_index[word]] += 1\n",
        "\n",
        "pos_probs = (pos_word_counts + 1) / (len(positive_docs) + 2)\n",
        "neg_probs = (neg_word_counts + 1) / (len(negative_docs) + 2)\n"
      ],
      "metadata": {
        "id": "2zGvAKpfVMYb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review):\n",
        "    # Tokenize the review\n",
        "    tokens = review.lower().split()\n",
        "    \n",
        "    # Calculate the log probabilities of each class given the review\n",
        "    pos_prob = np.log(0.5) + np.sum(np.log(pos_probs[vocab_index[token]] if token in vocab_list else 1) for token in tokens)\n",
        "    neg_prob = np.log(0.5) + np.sum(np.log(neg_probs[vocab_index[token]] if token in vocab_list else 1) for token in tokens)\n",
        "    \n",
        "    # Return the class with the highest probability\n",
        "    return 'fresh' if pos_prob > neg_prob else 'rotten'\n",
        "\n",
        "# Predict the sentiment of each review in the development set\n",
        "dev_preds = [predict_sentiment(review) for review in dev_data['Review']]\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = np.sum(dev_preds == dev_data['Freshness']) / len(dev_data)\n",
        "print(f\"Accuracy on dev set: {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJnqZZZdVRG0",
        "outputId": "f2f0a2fd-a4b2-4b69-8fb2-73fa814b595c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on dev set: 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review, alpha):\n",
        "    # Tokenize the review\n",
        "    tokens = review.lower().split()\n",
        "    \n",
        "    # Calculate the log probabilities of each class given the review\n",
        "    pos_prob = np.log(0.5) + np.sum(np.log((pos_probs[vocab_index.get(token, 0)]*(1-alpha)) + alpha) for token in tokens)\n",
        "    neg_prob = np.log(0.5) + np.sum(np.log((neg_probs[vocab_index.get(token, 0)]*(1-alpha)) + alpha) for token in tokens)\n",
        "\n",
        "    \n",
        "    # Return the class with the highest probability\n",
        "    return 'fresh' if pos_prob > neg_prob else 'rotten'\n",
        "\n",
        "\n",
        "# Test the effect of different smoothing parameters\n",
        "alphas = [0, 0.1, 0.01, 0.001, 0.0001]\n",
        "for alpha in alphas:\n",
        "    dev_preds = [predict_sentiment(review, alpha=alpha) for review in dev_data['Review']]\n",
        "    accuracy = np.sum(dev_preds == dev_data['Freshness']) / len(dev_data)\n",
        "    print(f\"Smoothing parameter: {alpha:.4f}, Accuracy on dev set: {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_tD7FeXeMQ4",
        "outputId": "d5170d62-477c-43e1-a2af-2c8e2c5bc0dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoothing parameter: 0.0000, Accuracy on dev set: 0.796\n",
            "Smoothing parameter: 0.1000, Accuracy on dev set: 0.588\n",
            "Smoothing parameter: 0.0100, Accuracy on dev set: 0.671\n",
            "Smoothing parameter: 0.0010, Accuracy on dev set: 0.743\n",
            "Smoothing parameter: 0.0001, Accuracy on dev set: 0.780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the difference in conditional probability between the two classes for each word\n",
        "diff_probs = pos_probs - neg_probs\n",
        "top_pos_words = [vocab_list[i] for i in np.argsort(diff_probs)[-10:][::-1]]\n",
        "top_neg_words = [vocab_list[i] for i in np.argsort(diff_probs)[:10]]\n",
        "\n",
        "print(\"Top 10 words that predict a positive review:\")\n",
        "print(top_pos_words)\n",
        "\n",
        "print(\"Top 10 words that predict a negative review:\")\n",
        "print(top_neg_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhsLvl1GeYYv",
        "outputId": "248ae598-dfb3-445c-9714-890135bf128c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words that predict a positive review:\n",
            "['and', 'of', 'a', 'is', 'with', 'in', 'an', 'film', 'best', 'the']\n",
            "Top 10 words that predict a negative review:\n",
            "['to', 'too', 'like', 'or', 'movie', 'have', 'so', 'much', 'just', 'only']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = [predict_sentiment(review, alpha=0.001) for review in test_data['Review']]\n",
        "test_accuracy = np.sum(test_preds == test_data['Freshness']) / len(test_data)\n",
        "print(f\"Final accuracy on test set: {test_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyQSmMUHehcr",
        "outputId": "c8bf00f1-8b9f-4ca4-f5d3-1b1b6602aa85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy on test set: 0.743\n"
          ]
        }
      ]
    }
  ]
}